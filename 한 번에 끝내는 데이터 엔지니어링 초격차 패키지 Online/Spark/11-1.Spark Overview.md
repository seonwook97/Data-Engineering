1. [Spark 소개](#Spark-소개)

---

## 1. Spark 소개

### 1-1. Spark란
- Spark 는 데이터 엔지니어링, 데이터 사이언스, 머신러닝등의 작업을 실행할 수 있는 multilangauge 엔진/프레임워크이다.
- 단일 노드 뿐만 아니러 cluster 형태로 대량의 컴퓨팅 자원을 사용할 수 있다.
- 대량의 데이터에 대해서 분산된 컴퓨팅 처리를 신뢰성 있게 처리할 수 있다.

### 1-2. Spark의 주요 기능
- Batch/streaming data
  - 하나의 프로그래밍 모델과 프레임워크로 Batch 처리와 real-time streaming 을 통합 개발할 수 있다.
  - Python, SQL, Scala, Java , R의 다양한 언어로 개발할 수 있다.
- SQL analytics
  - 반복된 쿼리, ad-hoc 쿼리 모두 ANSI SQL로 빠르게 분산된 처리결과를 얻을 수 있다.
  - 기존의 다양한 data warehouse 솔루션보다 빠르다.
- Data science at scale
  - petabyte-scale 데이터에 대해 downsampling없이도 Exploratory Data Analysis (EDA)를 수행할 수 있다.
- Machine learning
  - ML algorithm 을 학습시킬 수 있고, 로컬에서 작성하고 수행한 코드가 수천대의 클러스터에서도 동일하게 동작한다.
 
### 1-3. Spark가 풀고자 하는 문제

#### 1-3-1. MapReduce의 한계 극복
- 대량의 데이터에 대한 처리 작업은 MapReduce 라는 모델이 처리하는 것이 효율적이고 강력하다는 것이 Hadoop MapReduce 에서 검증이 되었다.
- Hadoop MapReduce 는 이전에는 처리할 수 없던 대량의 데이터를 처리할 수 있게 한 의미가 있다. 하지만, Hadoop MapReduce 는 빈번한 자원의 할당과 해제의 문제, 중간 결과 파일을 외부 스토리지를 사용함으로서 발생하는 지연시간과 부하 문제, 과도한 shuffle 문제 등으로 인해 실제 데이터 처리 작업보다 부가적인 작업에 의해 시간을 너무 많이 소모하고 자원을 낭비하는 문제가 있었다.
- Spark 는 분산 데이터 모델인 RDD와 in-memory cache 의 활용으로 Hadoop MapReduce 의 한계를 대부분 해결했고, 그 결과 Hadoop MapReduce 보다 100배 이상의 빠른 성능을 보였다.
