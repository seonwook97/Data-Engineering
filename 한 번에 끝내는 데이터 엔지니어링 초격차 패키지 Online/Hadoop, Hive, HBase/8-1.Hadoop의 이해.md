1. [Hadoop을 사용하는 이유](#1-hadoop을-사용하는-이유)
2. [HDFS](#2-hdfs)

---

# 1. Hadoop을 사용하는 이유

## 1-1. Hadoop의 필요성
- 온라인 서비스와 온라인 데이터 처리 기술이 발전하면서, 데이터의 양과 종류가 다양해졌다. 정형 데이터의 경우 기존에 있던 RDBMS에 저장할 수 있지만, 웹 로그 등의 비정형 데이터를 RDBMS에 저장하기에는 데이터의 크기가 너무 크고, RDBMS의 복잡하고 상세한 기능이 필요하지도 않았다. 또한 RDBMS는 대용량, 고스펙의 장비에 운용하는데, 자주 사용하지 않는 데이터를 무작정 RDBMS를 늘려서 보관하는 것은 비용이 너무 크다.

- 하둡은 값비싼 장비가 아닌 x86 리눅스 서버라면 어떤 수준의 장비든지 하둡을 설치해서 운용할 수 있다.
(commodity servers) 또한 데이터 용량이 커지면 단순히 노드를 늘려서 대응할 수 있고, 이것을 재설치나 재구성 없이 할 수 있다는 점도 대용량을 위한 큰 장점이다. 또한 하둡은 데이터의 복제본을 저장하기 때문에 유실이나 장애에도 데이터 복구를 할 수 있다는 점 또한 장점이다.

- 또한 여러대의 서버에 데이터가 저장되어있기 때문에, 프로세싱 또한 데이터가 분산된 서버에서 동시에 처리할 수 있다. 이런 분산 컴퓨팅을 통해서 기존의 데이터 처리 방법보다 큰 성능의 향상을 얻을 수 있다.
    - 사례: 2008년 뉴욕타임즈에서 130년 분량의 신문기사 1100만 페이지를 AWS의 EC2, S3, Hadoop 을 이용해서 하루만에 모두 PDF로 변환 했다. 이 때 소요된 비용은 200만원이었다.
        - 당시 일반 서버에서 일반적인 병렬처리로 진행할 경우 약 14년이 걸리는 작업이었다.

## 1-2. Hadoop의 특징
- 하둡의 상세 기능은 많지만, 고수준(High-Level)에서 꼽을 수 있는 주요 특징은 다음과 같다.
    - Scalable: Hadoop can reliably store and process petabytes.
    - Economical: It distributes the data and processing across clusters of commonly available computers. These clusters can number into the thousands of nodes.
    - Efficient: By distributing the data, Hadoop can process it in parallel on the nodes where the data is located. This makes it extremely rapid.
    - Reliable: Hadoop automatically maintains multiple copies of data and automatically redeploys computing tasks based on failures.

## 1-3. Hadoop 생태계

### 1-3-1. Hadoop V2로의 진화

![image](https://user-images.githubusercontent.com/92377162/236780416-451fce8f-8647-4a75-a983-4d63f7fd7e19.png)

- Hadoop v1 은 단순히 분산 파일 관리 시스템인 HDFS와 분산 데이터 처리를 위한 MapReduce 프레임워크만 제공했다. MapReduce 는 데이터가 위치한 곳에서 연산을 처리할 수 있기 때문에 강력했지만, 사용이 불편했다.

- Hadoop v2로 업그레이드 되며 아키텍처에서 큰 변화가 있었다. 노드와 파일시스템은 HDFS 를 근간으로 하지만, 그 이외에 모든 작업을 Yarn 이라는 Resource Management 프레임워크를 이용해서 유연하게 분산 처리 작업을 작성하고 활용할 수 있는 아키텍처로 바꾼 것이다.

### 1-3-2. Yarn의 역할
- Yarn 의 도입으로 기본 프레임워크인 MapReduce 뿐만 아니라, Tez, Flink, Spark 분산 처리를 위한 프레임워크나 도구들이 HDFS 와 HDFS가 설치된 컴퓨팅 자원을 더 쉽게 이용할 수 있게 되었다. 이것은 HDFS의 활용도를 높임과 동시에 강력한 생태계를 구축할 수 있도록 만들었다.

### 1-3-3. Winner Takes All
- 대용량 데이터를 다루기 위해서는 기술적인 난이도가 높을 뿐만 아니라, 다양한 컴퓨팅 하드웨어, 소프트웨어와의 호환성 등으로 개발 공수가 크다. 또한 데이터가 많은 만큼 버그로 인한 사이드 이펙트 또한 커서, 안정적으로 사용하기 위해서는 성숙에 드는 시간이 필요하다. 하둡 에코시스템은 HDFS와 Yarn 을 기반으로 이 성숙의 과정을 거쳐오며 발전한 에코시스템인 만큼, 대용량 시스템에서 이 에코시스템을 대체할만한 대체자가 나오기 쉽지 않다. 이로 인해 새로운 대용량 분산시스템이 등장할 때는 새로운 시스템을 만들더라도 하둡 생태계를 지원하는 방향으로 기술 개발이 이루어지고 있다.

---

# 2. HDFS

## 2-1. HDFS 의 Design Goal

### 2-1-1. Hardware Failure
- HDFS를 구성하는 분산 서버에는 다양한 장애가 발생할 수 있다. 예를 들면 하드디스크에 오류가 생겨서 데이터 저장에 실패하는 경우, 디스크 복구가 불가능해 데이터가 유실되는 경우, 네트워크 장애가 생겨 특정 분산 서버에 네트워크 접근이 안되는 경우 등이 있다.

- HDFS는 이런 장애를 빠른 시간에 감지하고 대처할 수 있게 설계되어있다. HDFS에 데이터를 저장하면, 복제본도 함께 저장되어 데이터 유실을 방지한다. 분산 서버 사이에는 주기적으로 health check 를 통해 빠른 시간에 장애를 감지하고 대처할 수 있게 됩니다.

### 2-1-2. Streaming Data Access
- HDFS는 클라이언트의 요청을 빠르게 처리하는 것보다 동일한 시간 내에 더 많은 데이터를 처리하는 것을 목표로 한다. HDFS는 이것을 위해 Random Access 를 고려하지 않는다. user와 상호작용하는 것보다는 batch 처리에 더 맞게 디자인 되어있다. 따라서 은행 서비스, 쇼핑몰과 같은 trasnactional 서비스에서 기존 파일시스템 대신 HDFS 를 쓰는 것은 적합하지 않다.

- HDFS는 Random Access 대신 Streaming 방식으로 데이터를 접근하도록 설계되어 있다. Client 는 HDFS 명령어/API를 통해서 연속된 흐름(streaming)으로 데이터에 접근할 수 있다.

### 2-1-3. Large Data Sets
- HDFS는 하나의 파일이 GB ~ TB 수준의 데이터 크기로 저장될 수 있게 설계되었다. 이것으로 높은 데이터 전송 대역폭(bandwidth)를 지원하고 하나의 클러스터에서 수백대의 노드를 구성할 수 있다. 하나의 인스턴스에서는 수백만개(tens of million) 이상의 파일을 지원한다.

### 2-1-4. Simple Coherency Model
- 데이터베이스에서 데이터의 무결성은, 데이터의 입력이나 변경을 제한해서 데이터의 안정성을 깨는 동작을 막는 것을 의미한다.
- HDFS는 write-once-read-many access model 이 필요하다. HDFS에서는 한 번 저장한 데이터는 수정할 수 없고, 읽기만 가능하게 무결성을 지킨다. 데이터 수정은 불가능하지만, 파일의 이동, 삭제, 복사는 지원한다. 최초에는 수정이 안되었지만, 현재는 end of file 위치에 append 가 가능하다.
- 이런 Simple Data Coherency Model 은 데이터 접근에 대한 높은 throughput 을 가능하게 한다. 이 방식은 MapReduce 에서 큰 장점을 발휘한다.

### 2-1-5. Moving Computation is Cheaper than Moving Data
- 데이터를 이용해서 computing processing 을 한다면, 데이터가 processor와 가까울 수록 효율이 좋다. 데이터의 양이 클수록 이 영향이 크다. Network 혼잡을 줄이고 시스템 전체의 throughput 을 높일 수 있다.
- HDFS는 이것을 위해 computing 자원을 data가 있는 위치로 이동시키는 것을 선택한다. Data를 이동시키는 것보다 비용이 싸고 빠르기 때문이다. HDFS는 이러한 방식을 위한 인터페이스를 제공한다.

### 2-1-6. Portability Across Heterogeneous Hardware and Software Platforms
- HDFS는 쉽게 HW/SW 플랫폼을 옮길 수 있도록 디자인 되었다. 인텔 칩, AMD칩이 설치된 하드웨어에서 동일한 기능으로 동작한다. CentOS나 Redhat LInux 상관없이 동일하게 동작한다.
    - HDFS의 서버의 코드가 Java로 구현되어있기 때문에 가능하다.
- 대용량 데이터 셋의 플랫폼으로 채택되는 주요한 이유중 하나이다.

## 2-2. HDFS Architecture - Block based file system

### 2-2-1. Block based file system 이란?
- HDFS는 블록 구조의 파일 시스템이다. HDFS에 저장되는 모든 파일은 일정 크기의 블록으로 나눠져서 여러 서버에 분산되어 저장된다. 블록 크기는 기본 128MB로 되어있고, 설정으로 변경이 가능하다. 블록단위로 분산해서 저장하기 때문에 로컬 디스크보다 큰 규모의 데이터를 저장할 수 있고, 저장할 수 있는 용량을 페타바이트 단위까지 확장할 수 있다.

### 2-2-2. 파일과 Block
1. 하나의 파일은 하나 또는 복수의 block 에 저장된다. 이때 어떤 파일이 어느 블록에 저장되어있는지는 메타데이터로 namenode가 메모리에서 관리한다.
2. 복수의 파일이 하나의 block에 저장될 수 없다.
3. 하나의 File의 사이즈가 block size 를 넘어가면, 여러개의 블록에 나누어 저장된다.
    - 예) 하나의 파일 사이즈가 128MB+10bytes 라면, 128MB 블록 하나, 10bytes 블록 하나에 나뉘어 저장된다.
4. 하나의 File 사이즈 또는 하나의 블록 사이즈를 초과하는 크기의 하나의 파일이 블록 사이즈로 딱 나누어떨어지지 않아서 남은 사이즈가 하나의 블록 사이즈보다 작다면, 해당 블록은 그 크기만큼 점유한 블록으로 관리된다.
    - 예1) 하나의 파일이 1MB이고 블록사이즈가 128MB라면, 128MB 블록 하나에 할당되어 1MB만 저장된다.
    - 예2) 하나의 파일이 129MB이고 블록 사이즈가 128MB라면, 해당 파일은 128MB 블록 한개, 1MB 블록 한개에 구성된다.
5. 실제 디스크를 점유하는 공간은 블록 내에 파일이 차지하는 크기이다.
    - 예) 블록 사이즈 128MB이고, 할당된 파일의 사이즈가 1MB 이라면, 실제 디스크 사용량은 1MB이다.

### 2-2-3. Block system의 장점
- Block 크기를 적당한 수준(64MB, 128MB) 으로 고정해서 얻을 수 있는 장점은 다음과 같다.

1. Disk Seek time 감소
    - 디스크 탐색 시간 = seek time (데이터의 위치) + search time (데이터의 섹터에 도달). 하둡 개발 당시의 일반적인 HDD의 disk seek time은 10ms, disk I/O bandwidth 는 100MB/s 였다. HDFS는 seek time 이 bandwidth 의 1% 사용하는 것을 목표로 했다. 따라서 100MB를 넘지않고 2^n 으로 가까운 64MB를 선택했다. (Hadoop v1 은 64MB였다.)

2. Metadata size 감소
    - namenode 는 블록 위치, 파일명, 디렉토리 구조, 권한 정보 등의 메타데이터 정보를 메모리에서 관리한다. 예를 들어 블록 사이즈가 128MB이라면, 200MB의 파일에 대해 2개 블록에 해당하는 메타데이터만 저장하면 된다. 하지만 일반적인 파일시스템은 블록(page) 크기가 4k~8k이기 때문에 동일한 크기의 파일을 저장할 경우 훨씬 많은 메타데이터가 생성된다. 200MB의 파일에 대해서 만약 블록 크기가 4k 이라면, 5만개의 블록이 생성되고 메타데이터 또한 5만개 분을 하나의 namenode에서 관리해야한다. namenode는 모든 메타데이터를 관리하는 단일 서버이므로 이렇게 메타데이터의 양이 늘어나는 것은 성능과 HDFS 안정성에 심각한 영향을 미친다.
        - namenode는 일반적으로 100만개 블록을 저장할 경우, 1GB의 heap memory를 사용한다.

3. Communication cost between Client and NameNode
    - 클라이언트는 HDFS에 저장된 파일을 접근할 때, namenode에 먼저 해당 파일을 구성하는 데이터 블록의 위치를 조회한다. 데이터 블록이 작아서 그 갯수가 많다면, 이 조회에서 필요한 데이터가 많아지거나 조회 횟수가 증가할 것이다. 클라이언트는 스트리밍 방식으로 데이터를 읽고 쓰기 때문에 특별한 경우를 제외하면 namenode 와 통신할 필요가 없다.